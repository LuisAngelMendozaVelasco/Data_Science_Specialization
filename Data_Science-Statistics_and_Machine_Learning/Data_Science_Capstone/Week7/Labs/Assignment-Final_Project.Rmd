---
title: "Assignment: Final Project Submission"
output: html_notebook
---

# 1. Load data

```{bash}
mkdir -p data
wget -q https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip -P ./data/
unzip -q ./data/Coursera-SwiftKey.zip -d ./data/
```

```{r}
blog <- readLines("./data/final/en_US/en_US.blogs.txt", skipNul=TRUE, warn=TRUE)
news <- readLines("./data/final/en_US/en_US.news.txt", skipNul=TRUE, warn=TRUE)
twitter <- readLines("./data/final/en_US/en_US.twitter.txt", skipNul=TRUE, warn=TRUE)
```

# 2. Data sampling

```{r}
set.seed(100)
sample_size = 1000

sample_blog <- blog[sample(1:length(blog), sample_size)]
sample_news <- news[sample(1:length(news), sample_size)]
sample_twitter <- twitter[sample(1:length(twitter), sample_size)]
```

```{r}
head(sample_blog)
```

```{r}
head(sample_twitter)
```

```{r}
head(sample_news)
```

```{r}
sample_data <- rbind(sample_blog, sample_news, sample_twitter)
rm(blog, news, twitter)
```

# 3. Clean data

```{r}
library("tm")

mycorpus <- VCorpus(VectorSource(sample_data))
mycorpus <- tm_map(mycorpus, content_transformer(tolower)) # convert to lowercase
mycorpus <- tm_map(mycorpus, removePunctuation) # remove punctuation
mycorpus <- tm_map(mycorpus, removeNumbers) # remove numbers
mycorpus <- tm_map(mycorpus, stripWhitespace) # remove multiple whitespace
changetospace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
mycorpus <- tm_map(mycorpus, changetospace, "/|@|\\|")
```

# 4. Tokenize the sentences

```{r}
library("RWeka")

uniGramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min=1, max=1))
biGramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min=2, max=2))
triGramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min=3, max=3))
OneT <- NGramTokenizer(mycorpus, Weka_control(min=1, max=1))
oneGM <- TermDocumentMatrix(mycorpus, control=list(tokenize=uniGramTokenizer))
twoGM <- TermDocumentMatrix(mycorpus, control=list(tokenize=biGramTokenizer))
threeGM <- TermDocumentMatrix(mycorpus, control=list(tokenize=triGramTokenizer))
```

# 5. Generate n-gram histograms

```{r}
library("ggplot2")

freqTerms <- findFreqTerms(oneGM, lowfreq=200)
termFreq <- rowSums(as.matrix(oneGM[freqTerms,]))
termFreq <- data.frame(unigram=names(termFreq), frequency=termFreq)

g1 <- ggplot(termFreq, aes(x=reorder(unigram, frequency), y=frequency)) +
    geom_bar(stat="identity") + coord_flip() +
    theme(legend.title=element_blank()) +
    xlab("Unigram") + ylab("Frequency") +
    labs(title="Top unigrams by frequency")
print(g1)
```

```{r}
freqTerms <- findFreqTerms(twoGM, lowfreq=70)
termFreq <- rowSums(as.matrix(twoGM[freqTerms,]))
termFreq <- data.frame(bigram=names(termFreq), frequency=termFreq)

g2 <- ggplot(termFreq, aes(x=reorder(bigram, frequency), y=frequency)) +
    geom_bar(stat = "identity") + coord_flip() +
    theme(legend.title=element_blank()) +
    xlab("Bigram") + ylab("Frequency") +
    labs(title = "Top bigrams by frequency")
print(g2)
```

```{r}
freqTerms <- findFreqTerms(threeGM, lowfreq=10)
termFreq <- rowSums(as.matrix(threeGM[freqTerms,]))
termFreq <- data.frame(trigram=names(termFreq), frequency=termFreq)

g3 <- ggplot(termFreq, aes(x=reorder(trigram, frequency), y=frequency)) +
    geom_bar(stat="identity") + coord_flip() +
    theme(legend.title=element_blank()) +
    xlab("Trigram") + ylab("Frequency") +
    labs(title="Top trigrams by frequency")
print(g3)
```

```{bash}
rm -rf ./data/
```