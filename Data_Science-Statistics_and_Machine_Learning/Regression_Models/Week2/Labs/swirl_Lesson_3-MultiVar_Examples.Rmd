---
title: "swirl Lesson 3: MultiVar Examples"
output: html_notebook
---

"MultiVar_Examples. (Slides for this and other Data Science courses may be found at github https://github.com/DataScienceSpecialization/courses. If you care to use them, they must be downloaded as a zip file and viewed locally. This lesson corresponds to Regression_Models/02_02_multivariateExamples.)"

In this lesson, we'll look at some examples of regression models with more than one variable. We'll begin with the Swiss data which we've taken the liberty to load for you. This data is part of R's datasets package. It was gathered in 1888, a time of demographic change in Switzerland, and measured six quantities in 47 French-speaking provinces of Switzerland. We used the code from the slides (the R function pairs) to display here a 6 by 6 array of scatterplots showing pairwise relationships between the variables. All of the variables, except for fertility, are proportions of population. For example, "Examination" shows the percentage of draftees receiving the highest mark on an army exam, and "Education" the percentage of draftees with education beyond primary school.

From the plot, which is NOT one of the factors measured?

```{r}
"Obesity"
```

First, use the R function lm to generate the linear model "all" in which Fertility is the variable dependent on all the others. Use the R shorthand "." to represent the five independent variables in the formula passed to lm.  Remember the data is "swiss". 

```{r}
all <- lm(Fertility ~ ., swiss)
```

Now look at the summary of the linear model all.

```{r}
summary(all)
```

Recall that the Estimates are the coefficients of the independent variables of the linear model (all of which are percentages) and they reflect an estimated change in the dependent variable (fertility) when the corresponding independent variable changes. So, for every 1% increase in percent of males involved in agriculture as an occupation we expect a .17 decrease in fertility, holding all the other variables constant; for every 1% increase in Catholicism, we expect a .10 increase in fertility, holding all other variables constant.  

The "*" at the far end of the row indicates that the influence of Agriculture on Fertility is significant. At what alpha level is the t-test of Agriculture significant?

```{r}
"0.05"
```

Now generate the summary of another linear model (don't store it in a new variable) in which Fertility depends only on agriculture.

```{r}
summary(lm(Fertility ~ Agriculture, swiss))
```

What is the coefficient of agriculture in this new model?

```{r}
"0.19420"
```

The interesting point is that the sign of the Agriculture coefficient changed from negative (when all the variables were included in the model) to positive (when the model only considered Agriculture). Obviously the presence of the other factors affects the influence Agriculture has on Fertility.

Let's consider the relationship between some of the factors. How would you expect level Education and performance on an Examination to be related?

```{r}
"They would be correlated"
```

Now check your intuition with the R command "cor". This computes the correlation between Examination and Education. 

```{r}
cor(swiss$Examination, swiss$Education)
```

The correlation of .6984 shows the two are correlated. Now find the correlation between Agriculture  and Education. 

```{r}
cor(swiss$Agriculture, swiss$Education)
```

The negative correlation (-.6395) between Agriculture and Education might be affecting Agriculture's influence on Fertility. I've loaded and sourced the file swissLMs.R in your working directory. In it is a function makelms() which generates a sequence of five linear models. Each model has one more independent variable than the preceding model, so the first has just one independent variable, Agriculture, and the last has all 5. I've tried loading the source code in your editor. If I haven't done this, open the file manually so you can look at the code. 

Now run the function makelms() to see how the addition of variables affects the coefficient of Agriculture in the models.

```{r}
makelms <- function(){
    # Store the coefficient of linear models with different independent variables
    cf <- c(coef(lm(Fertility ~ Agriculture, swiss))[2], 
          coef(lm(Fertility ~ Agriculture + Catholic,swiss))[2],
          coef(lm(Fertility ~ Agriculture + Catholic + Education,swiss))[2],
          coef(lm(Fertility ~ Agriculture + Catholic + Education + Examination,swiss))[2],
          coef(lm(Fertility ~ Agriculture + Catholic + Education + Examination + Infant.Mortality, swiss))[2])
    print(cf)
}
```

```{r}
makelms()
```

The addition of which variable changes the sign of Agriculture's coefficient from positive to negative?

```{r}
"Education"
```

Now we'll show what happens when we add a variable that provides no new linear information to a model. Create a variable ec that is the sum of swiss$Examination and swiss$Catholic.

```{r}
ec <- swiss$Examination + swiss$Catholic
```

Now generate a new model efit with Fertility as the dependent variable and the remaining 5 of the original variables AND ec as the independent variables. Use the R shorthand ". + ec" for the righthand side of the formula.

```{r}
efit <- lm(Fertility ~ . + ec, swiss)
```

We'll see that R ignores this new term since it doesn't add any information to the model.

Subtract the efit coefficients from the coefficients of the first model you created, all.

```{r}
all$coefficients - efit$coefficients
```

Which is the coefficient of ec?

```{r}
"NA"
```

This tells us that

```{r}
"Adding ec doesn't change the model"
```
